---
title: "Scientific mapping analysis of Net Promoter Score (NPS): Supplemental Material"
author: | 
  | Juan C. Correa
  | University of Economics, Prague
output: pdf_document
---

This supplemental material aims to provide an open and reproducible report that shows the empirical results obtained for the paper titled: "Balancing the evidence of the Net Promoter Score: The results of a scientific mapping analysis versus an empirical work in the energy sector." A warning note is that this supplemental material is limited to the scientific mapping analysis, and does not provide any result regarding the empirical analysis of the data retrieved from the Energy sector (as this data was obtained under an anonymity agreement between the research team and the energy supplier company).

Our first step consists of using the raw data set called "NPS.RData" and apply the following series of commands

```{r}
load("~/NPS.RData")
NPS <- data.frame(M)
library(dplyr)
NPS <- arrange(NPS, desc(TC))
selectedPapers <- filter(NPS, grepl('REICHHELD', CR))
rm(list=setdiff(ls(), "selectedPapers"))
selectedPapers$Against <- NA
balancedPapers <- selectedPapers[, c(1, 6, 53, 37)]
```
Until this point, we now have two data sets (i.e., "balancedPapers" and "selectedPapers"). In "selectedPapers" there are 91 papers. The common attribute among them is that they all cite the paper of Reichheld (2003). In "balancedPapers" we have the same papers included in "selectedPapers", but it contains only four columns: 1) AU is the column for authors, 2) AB is the column for the abstract of each paper, 3) Against is the column that in which we are going to indicate if the paper provides specific arguments in favor or against the use of NPS (as illustrated below), and 4) TC is the column that contains the number of citations as captured by Web-of-Science database.

# Classification of papers as supporters of NPS
Then, we classified each paper's opinion on the use of NPS. Papers that used NPS without providing any explicit critic in the abstract were classified as 0, while papers that provide explicit criticism on NPS were classified as 1, like this:
```{r}
balancedPapers$Against <- c(1,0,0,1,1,1,1,0,0,1,
                            1,0,0,0,0,0,0,0,0,0,
                            0,1,0,0,0,0,0,1,0,1,
                            0,0,0,1,0,0,0,1,0,0,
                            0,0,1,0,0,0,0,0,0,0,
                            0,0,0,0,1,0,0,1,0,0,
                            0,1,0,0,1,0,0,1,0,0,
                            0,0,0,0,0,0,0,0,0,0,
                            0,0,0,0,1,0,0,0,0,0,
                            0)
```

After completing this thorough classification, we can proceed with some bibliometric analysis

# Bibliometric Analysis
```{r}
library(bibliometrix)
results <- biblioAnalysis(selectedPapers, sep = ";")

S <- summary(object = results, k = 10, pause = FALSE)

plot(x = results, k = 10, pause = FALSE)

NetMatrix <- biblioNetwork(selectedPapers, analysis = "co-occurrences", network = "keywords", sep = ";")

net=networkPlot(NetMatrix, normalize="association", weighted=T, n = 30, Title = "Keyword Co-occurrences", type = "fruchterman", size=T,edgesize = 5,labelsize=0.7)

CS <- conceptualStructure(selectedPapers,field="ID", method="CA", minDegree=4, clust=5, stemming=FALSE, labelsize=10, documents=10)
```

The results above show a series of revealing facts regarding the publication of NPS. For example, the emergence of five dominant topics, and the keywords co-occurrence network. 

```{r}
library(ggplot2)
p <- ggplot(balancedPapers, 
            aes(x=TC, fill=as.character(Against))) + geom_density(alpha=0.3) + theme_classic() +
xlab("Number of Citations") +
theme(text = element_text(size=15),
      axis.text.x = element_text(size = 10), 
      axis.text.y = element_text(size = 10))

        p + theme(legend.position=c(x=0.8, y=0.8)) +
scale_fill_discrete(name = "Technical Orientation", labels = c("Promoting NPS use", "Criticizing NPS use"))  
```



